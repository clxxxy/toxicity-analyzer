{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b7d796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando o dataset...\n",
      "Dataset carregado com sucesso!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comentario</th>\n",
       "      <th>anotator1</th>\n",
       "      <th>anotator2</th>\n",
       "      <th>anotator3</th>\n",
       "      <th>label_final</th>\n",
       "      <th>links_post</th>\n",
       "      <th>account_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mais um lixo</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Essa nao tem vergonha na cara!!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Essa mulher é doente.pilantra!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Comunista safada...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vagabunda. Comunista. Mentirosa. O povo chilen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         comentario  anotator1  \\\n",
       "0   1                                       Mais um lixo          1   \n",
       "1   2                    Essa nao tem vergonha na cara!!          1   \n",
       "2   3                     Essa mulher é doente.pilantra!          1   \n",
       "3   4                                Comunista safada...          1   \n",
       "4   5  Vagabunda. Comunista. Mentirosa. O povo chilen...          1   \n",
       "\n",
       "   anotator2  anotator3  label_final  \\\n",
       "0          1          1            1   \n",
       "1          1          1            1   \n",
       "2          1          1            1   \n",
       "3          1          1            1   \n",
       "4          1          1            1   \n",
       "\n",
       "                                 links_post    account_post  \n",
       "0  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
       "1  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
       "2  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
       "3  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
       "4  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribuição das classes:\n",
      "label_final\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Iniciando pré-processamento...\n",
      "Dados divididos: 5600 para treino, 1400 para teste.\n",
      "Vetorizando o texto...\n",
      "Treinando o modelo de classificação...\n",
      "Modelo treinado com sucesso!\n",
      "\n",
      "Avaliando o modelo nos dados de teste...\n",
      "\n",
      "Acurácia: 0.8314285714285714\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Não Odioso       0.83      0.83      0.83       700\n",
      "      Odioso       0.83      0.83      0.83       700\n",
      "\n",
      "    accuracy                           0.83      1400\n",
      "   macro avg       0.83      0.83      0.83      1400\n",
      "weighted avg       0.83      0.83      0.83      1400\n",
      "\n",
      "\n",
      "--- MVP PRONTO PARA USO ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# URL do dataset HateBR no GitHub\n",
    "DATASET_URL = 'https://raw.githubusercontent.com/franciellevargas/HateBR/main/dataset/HateBR.csv'\n",
    "\n",
    "# 1. Carregar o dataset\n",
    "print(\"Carregando o dataset...\")\n",
    "try:\n",
    "    df = pd.read_csv(DATASET_URL)\n",
    "    print(\"Dataset carregado com sucesso!\")\n",
    "    # Mostra as primeiras linhas e a distribuição das classes\n",
    "    display(df.head())\n",
    "    print(\"\\nDistribuição das classes:\")\n",
    "    print(df['label_final'].value_counts(normalize=True))\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o dataset: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 2. Pré-processamento e Definição das variáveis\n",
    "print(\"\\nIniciando pré-processamento...\")\n",
    "# Para este MVP, a única limpeza será converter para minúsculas.\n",
    "# O TfidfVectorizer já lida com muita coisa.\n",
    "X = df['comentario'].str.lower()\n",
    "y = df['label_final']\n",
    "\n",
    "# 3. Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Dados divididos: {len(X_train)} para treino, {len(X_test)} para teste.\")\n",
    "\n",
    "# 4. Vetorização do texto usando TF-IDF\n",
    "print(\"Vetorizando o texto...\")\n",
    "vectorizer = TfidfVectorizer(max_features=5000) # Usamos as 5000 palavras mais relevantes\n",
    "\n",
    "# Aprende o vocabulário com os dados de treino e transforma os dados de treino\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Apenas transforma os dados de teste com o vocabulário já aprendido\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# 5. Treinamento do modelo de Regressão Logística\n",
    "print(\"Treinando o modelo de classificação...\")\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vect, y_train)\n",
    "print(\"Modelo treinado com sucesso!\")\n",
    "\n",
    "# 6. Avaliação do modelo\n",
    "print(\"\\nAvaliando o modelo nos dados de teste...\")\n",
    "y_pred = model.predict(X_test_vect)\n",
    "\n",
    "print(\"\\nAcurácia:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Não Odioso', 'Odioso']))\n",
    "\n",
    "# Agora que o modelo está treinado, podemos usá-lo.\n",
    "# Os objetos que precisamos salvar/usar para novas previsões são:\n",
    "# - `model` (o classificador)\n",
    "# - `vectorizer` (o vetorizador)\n",
    "\n",
    "print(\"\\n--- MVP PRONTO PARA USO ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c96fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_toxicidade(comentario: str, model, vectorizer) -> dict:\n",
    "    \"\"\"\n",
    "    Recebe um comentário e retorna a classificação de toxicidade\n",
    "    e a probabilidade de ser discurso de ódio.\n",
    "    \"\"\"\n",
    "    # 1. Aplicar o mesmo pré-processamento (minúsculas)\n",
    "    comentario_processado = comentario.lower()\n",
    "    \n",
    "    # 2. Vetorizar o comentário usando o vetorizador JÁ TREINADO\n",
    "    comentario_vect = vectorizer.transform([comentario_processado])\n",
    "    \n",
    "    # 3. Fazer a predição\n",
    "    predicao = model.predict(comentario_vect)\n",
    "    probabilidades = model.predict_proba(comentario_vect)\n",
    "    \n",
    "    # A probabilidade de ser discurso de ódio é a probabilidade da classe \"1\"\n",
    "    prob_odio = probabilidades[0][1]\n",
    "    \n",
    "    if predicao[0] == 1:\n",
    "        classificacao = \"Discurso de Ódio\"\n",
    "    else:\n",
    "        classificacao = \"Não é Discurso de Ódio\"\n",
    "        \n",
    "    return {\n",
    "        \"classificacao\": classificacao,\n",
    "        \"nivel_toxicidade\": f\"{prob_odio:.2%}\" # Formata como porcentagem\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e31c825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testando o MVP com novos comentários ---\n",
      "Comentário: 'Esses políticos são todos uns bandidos, tinham que sumir do mapa!'\n",
      "Resultado: {'classificacao': 'Discurso de Ódio', 'nivel_toxicidade': '88.81%'}\n",
      "\n",
      "Comentário: 'O jogo de futebol ontem foi muito emocionante, gostei bastante do resultado.'\n",
      "Resultado: {'classificacao': 'Não é Discurso de Ódio', 'nivel_toxicidade': '35.20%'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- EXEMPLOS DE USO ---\n",
    "print(\"\\n--- Testando o MVP com novos comentários ---\")\n",
    "\n",
    "# Exemplo 1: Comentário potencialmente tóxico\n",
    "comentario1 = \"Esses políticos são todos uns bandidos, tinham que sumir do mapa!\"\n",
    "resultado1 = avaliar_toxicidade(comentario1, model, vectorizer)\n",
    "print(f\"Comentário: '{comentario1}'\")\n",
    "print(f\"Resultado: {resultado1}\\n\")\n",
    "\n",
    "# Exemplo 2: Comentário neutro\n",
    "comentario2 = \"O jogo de futebol ontem foi muito emocionante, gostei bastante do resultado.\"\n",
    "resultado2 = avaliar_toxicidade(comentario2, model, vectorizer)\n",
    "print(f\"Comentário: '{comentario2}'\")\n",
    "print(f\"Resultado: {resultado2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b2b927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salvando o modelo e o vetorizador em arquivos...\n",
      "Modelo e vetorizador salvos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# (Após o bloco de treinamento e avaliação do modelo...)\n",
    "import joblib\n",
    "\n",
    "print(\"\\nSalvando o modelo e o vetorizador em arquivos...\")\n",
    "\n",
    "# Salva o modelo treinado\n",
    "joblib.dump(model, 'modelo_odio.joblib')\n",
    "\n",
    "# Salva o vetorizador\n",
    "joblib.dump(vectorizer, 'vetorizador_odio.joblib')\n",
    "\n",
    "print(\"Modelo e vetorizador salvos com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78dff293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo e vetorizador carregados com sucesso.\n",
      "\n",
      "--- INICIANDO ANÁLISE DE TOXICIDADE NO REDDIT ---\n",
      "Conexão com a API do Reddit estabelecida. Modo Read-Only: True\n",
      "\n",
      "Buscando posts populares no r/brasil...\n",
      "Analisando comentários do post: 'Arte de Laerte'\n",
      "\n",
      "--- Relatório Final da Análise ---\n",
      "  - Subreddit analisado: r/brasil\n",
      "  - Post: 'Arte de Laerte...'\n",
      "  - Comentários analisados: 30\n",
      "  - Comentários classificados como discurso de ódio: 14\n",
      "  - Nível médio de toxicidade nos comentários: 49.63%\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Comentários Classificados como Discurso de Ódio ---\n",
      "1. o traço dela é tão foda que ela desenha a coisa mais manjada e óbvia do mundo e eu ainda pago pau\n",
      "---\n",
      "2. #\"O crime está em todo lugar.... Até dentro dessa casa.\"\n",
      "---\n",
      "3. Detalhe... Essa charge é de Outubro de 2024... O Chupetinha veio a público defender Fintech de PCC poucos meses depois. Todo mundo já sabia o que tava rolando.\n",
      "---\n",
      "4. Na época a maior apreensão de fuzis no RJ foi no condomínio do Bolsonaro.\n",
      "\n",
      "PM jagunço do Caiado matou informante do PCC com 12 tiros.\n",
      "\n",
      "Deputado inventa fake news para evitar fiscalização e facilitar lavagem de dinheiro do PCC.\n",
      "\n",
      "É isso, trabalham para o crime. Um fuzil não chega na mão de um fodido que mora em bairro sem esgoto através de mágica.\n",
      "---\n",
      "5. Exatamente. \n",
      "\n",
      "Mas a PM nunca vai chacinar a farinha lima igual faz na favela… pq será né?\n",
      "---\n",
      "6. Essa ela fez fácil de entender kkkk\n",
      "---\n",
      "7. Só faltou um brasão do estado ou uma plaquinha de deputado...\n",
      "---\n",
      "8. se chama crime organizado por um motivo\n",
      "---\n",
      "9. Matar ou roubar uma pessoa é um crime, tem gente que vai querer a morte desses bandidos.\n",
      "\n",
      "Agora... matar ou roubar em escala... dai são só negócios.\n",
      "---\n",
      "10. Essa Laerte é muito esperta mas está perigosamente próxima de virar um Armandinho\n",
      "---\n",
      "11. Foda que essa tirinha ai tem anos kkkkk\n",
      "\n",
      "Edit: 1 Ano, Outubro de 2024\n",
      "---\n",
      "12. Mais uma pra lista: Adriano da Nóbrega, o milico do Bope que matou a Marielle Franco, foi encontrado escondido e foi morto no sítio de um vereador do PL na Bahia, o partido do Bozo na época. Nos dias anteriores à morte, ele ligou para o advogado dele e disse que temia ser morto como queima de arquivo. O Adriano era amigo próximo da família do Bozo, foi condecorado pelo Flávio, a esposa e mãe dele eram funcionárias fantasmas da família Bozo. Os policiais que mataram ele disseram que ele resistiu e houve troca de tiros, porém a autópsia meses depois demonstrou que não havia pólvora nos dedos de Adriano no momento de sua morte, contradizendo a versão da polícia.\n",
      "---\n",
      "13. Que mora no extremo sul da cidade de São Paulo (Grajaú, Parelheiros e Marsilac) \"não\" sabe e \"nem\" viu nada sobre isso....\n",
      "---\n",
      "14. Envelheceu que nem vinho então kk\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import joblib\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# --- CONFIGURAÇÃO ---\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "CLIENT_ID = os.getenv(\"CLIENT_ID\")\n",
    "CLIENT_SECRET = os.getenv(\"CLIENT_SECRET\")\n",
    "USER_AGENT = os.getenv(\"USER_AGENT\")\n",
    "\n",
    "# Carregar o modelo e o vetorizador salvos\n",
    "try:\n",
    "    model = joblib.load('modelo_odio.joblib')\n",
    "    vectorizer = joblib.load('vetorizador_odio.joblib')\n",
    "    print(\"Modelo e vetorizador carregados com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERRO: Arquivos 'modelo_odio.joblib' ou 'vetorizador_odio.joblib' não encontrados.\")\n",
    "    print(\"Certifique-se de executar o script de treinamento ('analisador_odio.py') primeiro.\")\n",
    "    exit()\n",
    "\n",
    "# --- FUNÇÕES ---\n",
    "\n",
    "def avaliar_toxicidade(comentario: str) -> dict:\n",
    "    \"\"\"\n",
    "    Recebe um comentário e retorna a classificação de toxicidade\n",
    "    e a probabilidade de ser discurso de ódio.\n",
    "    \"\"\"\n",
    "    comentario_processado = comentario.lower()\n",
    "    comentario_vect = vectorizer.transform([comentario_processado])\n",
    "    predicao = model.predict(comentario_vect)\n",
    "    probabilidades = model.predict_proba(comentario_vect)\n",
    "    prob_odio = probabilidades[0][1]\n",
    "    \n",
    "    return {\n",
    "        \"eh_odio\": predicao[0] == 1,\n",
    "        \"nivel_toxicidade\": prob_odio\n",
    "    }\n",
    "\n",
    "# --- EXECUÇÃO PRINCIPAL ---\n",
    "\n",
    "def main():\n",
    "    print(\"\\n--- INICIANDO ANÁLISE DE TOXICIDADE NO REDDIT ---\")\n",
    "\n",
    "    # Conectar à API do Reddit\n",
    "    try:\n",
    "        reddit = praw.Reddit(\n",
    "            client_id=CLIENT_ID,\n",
    "            client_secret=CLIENT_SECRET,\n",
    "            user_agent=USER_AGENT,\n",
    "            check_for_async=False\n",
    "        )\n",
    "        print(f\"Conexão com a API do Reddit estabelecida. Modo Read-Only: {reddit.read_only}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao conectar com a API do Reddit: {e}\")\n",
    "        return\n",
    "\n",
    "    subreddit_alvo = \"brasil\"\n",
    "    limite_comentarios = 100\n",
    "\n",
    "    print(f\"\\nBuscando posts populares no r/{subreddit_alvo}...\")\n",
    "    \n",
    "    subreddit = reddit.subreddit(subreddit_alvo)\n",
    "    try:\n",
    "        post_popular = next(p for p in subreddit.hot(limit=5) if not p.stickied)\n",
    "        print(f\"Analisando comentários do post: '{post_popular.title}'\")\n",
    "    except StopIteration:\n",
    "        print(f\"Não foi possível encontrar um post válido no r/{subreddit_alvo}.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro ao buscar o post: {e}\")\n",
    "        return\n",
    "\n",
    "    total_toxicidade = 0\n",
    "    comentarios_odiosos = 0\n",
    "    comentarios_analisados = 0\n",
    "    \n",
    "    # NOVO: Lista para armazenar os comentários classificados como ódio\n",
    "    comentarios_odiosos_lista = []\n",
    "\n",
    "    post_popular.comments.replace_more(limit=0)\n",
    "\n",
    "    for comment in post_popular.comments.list():\n",
    "        if comentarios_analisados >= limite_comentarios:\n",
    "            break\n",
    "        \n",
    "        texto_comentario = comment.body\n",
    "        \n",
    "        if not texto_comentario or texto_comentario in ['[deleted]', '[removed]']:\n",
    "            continue\n",
    "\n",
    "        resultado = avaliar_toxicidade(texto_comentario)\n",
    "        total_toxicidade += resultado[\"nivel_toxicidade\"]\n",
    "        \n",
    "        if resultado[\"eh_odio\"]:\n",
    "            comentarios_odiosos += 1\n",
    "            # NOVO: Adiciona o texto do comentário à lista\n",
    "            comentarios_odiosos_lista.append(texto_comentario)\n",
    "        \n",
    "        comentarios_analisados += 1\n",
    "\n",
    "    media_toxicidade = (total_toxicidade / comentarios_analisados) if comentarios_analisados > 0 else 0\n",
    "    \n",
    "    print(\"\\n--- Relatório Final da Análise ---\")\n",
    "    print(f\"  - Subreddit analisado: r/{subreddit_alvo}\")\n",
    "    print(f\"  - Post: '{post_popular.title[:60]}...'\")\n",
    "    print(f\"  - Comentários analisados: {comentarios_analisados}\")\n",
    "    print(f\"  - Comentários classificados como discurso de ódio: {comentarios_odiosos}\")\n",
    "    print(f\"  - Nível médio de toxicidade nos comentários: {media_toxicidade:.2%}\")\n",
    "\n",
    "    # NOVO: Loop para imprimir os comentários ofensivos encontrados\n",
    "    print(\"\\n\" + \"=\"*50) # Adiciona uma linha separadora\n",
    "\n",
    "    if comentarios_odiosos_lista:\n",
    "        print(\"\\n--- Comentários Classificados como Discurso de Ódio ---\")\n",
    "        for i, comentario in enumerate(comentarios_odiosos_lista, 1):\n",
    "            print(f\"{i}. {comentario}\\n---\") # Adiciona um separador entre os comentários\n",
    "    else:\n",
    "        print(\"\\nNenhum comentário foi classificado como discurso de ódio nesta amostra.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663023fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando dados do usuário:  Low-Stay-5562\n",
      "Analisando até 100 comentários mais recentes...\n",
      "Analisados 10 comentários...\n",
      "Analisados 20 comentários...\n",
      "Analisados 30 comentários...\n",
      "Analisados 40 comentários...\n",
      "Analisados 50 comentários...\n",
      "Analisados 60 comentários...\n",
      "Analisados 70 comentários...\n",
      "Analisados 80 comentários...\n",
      "Analisados 90 comentários...\n",
      "Analisados 100 comentários...\n",
      "\n",
      "================================================================================\n",
      " RELATÓRIO DE ANÁLISE DE TOXICIDADE - USUÁRIO: u/ Low-Stay-5562\n",
      "================================================================================\n",
      "\n",
      "🟡 CLASSIFICAÇÃO: MODERADAMENTE TÓXICO\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " RESUMO ESTATÍSTICO:\n",
      "  • Comentários analisados: 100\n",
      "  • Comentários ofensivos: 41\n",
      "  • Percentual de toxicidade: 41.00%\n",
      "  • Nível médio de toxicidade: 0.50\n",
      "  • Karma médio por comentário: 12.8\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " INFORMAÇÕES DO PERFIL:\n",
      "  • Conta criada em: 2022-01-18\n",
      "  • Dias desde criação: 1320\n",
      "  • Karma de comentários: 4,998\n",
      "  • Karma de posts: 196\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " ATIVIDADE POR SUBREDDIT (Top 5):\n",
      "  1. r/brasil: 57 comentários\n",
      "  2. r/maconha: 7 comentários\n",
      "  3. r/antitrampo: 6 comentários\n",
      "  4. r/Patagonia: 5 comentários\n",
      "  5. r/Livros: 4 comentários\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " COMENTÁRIOS MAIS TÓXICOS:\n",
      "\n",
      "  1. Toxicidade: 0.94 | r/brasil\n",
      "     \"Fdp tá inchado de cachaça e vem falar uma asneira dessa. Que gente maldita que elegeu esse maldito!\"\n",
      "     URL: https://reddit.com/r/brasil/comments/1migk50/senador_magno_malta_afirma_que_moraes_descumpre_a/n73tqly/\n",
      "\n",
      "  2. Toxicidade: 0.93 | r/antitrampo\n",
      "     \"Galera gosta de passar vergonha com essas historinhas merda\"\n",
      "     URL: https://reddit.com/r/antitrampo/comments/1mmsbd9/ai_linkedin/n87bd8p/\n",
      "\n",
      "  3. Toxicidade: 0.93 | r/brasil\n",
      "     \"Povo da direita é tudo covarde e arregão mesmo. Fazem um monte de merda e depois metem um atestado. \n",
      "\n",
      "Bando de covardes!\"\n",
      "     URL: https://reddit.com/r/brasil/comments/1mvzgcw/zambelli_tem_adoecimentos_psiquiátricos_graves/n9u2zdz/\n",
      "\n",
      " PERÍODO ANALISADO: 2025-07-31 até 2025-08-31\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import joblib\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "#TESTAR COM PERFIS = FAUSEN, No-Job-193, Low-Stay-5562, Madrugada123,\n",
    "\n",
    "\n",
    "def analisar_perfil_usuario(username, reddit, model, vectorizer, limite=100):\n",
    "    \"\"\"\n",
    "    Analisa o perfil de um usuário do Reddit baseado em seus últimos comentários\n",
    "    \n",
    "    Args:\n",
    "        username (str): Nome do usuário do Reddit (sem u/) - Unica coisa que precisa preencher de vdd\n",
    "        reddit: Instância do PRAW\n",
    "        model: Modelo treinado de classificação\n",
    "        vectorizer: Vetorizador TF-IDF treinado\n",
    "        limite (int): Número máximo de comentários para analisar\n",
    "    \n",
    "    Returns:\n",
    "        dict: Análise completa do perfil do usuário\n",
    "    \"\"\"\n",
    "    \n",
    "    def avaliar_toxicidade_local(comentario):\n",
    "        comentario_processado = comentario.lower()\n",
    "        comentario_vect = vectorizer.transform([comentario_processado])\n",
    "        predicao = model.predict(comentario_vect)\n",
    "        probabilidades = model.predict_proba(comentario_vect)\n",
    "        prob_odio = probabilidades[0][1]\n",
    "        \n",
    "        return {\n",
    "            \"odio\": predicao[0] == 1,\n",
    "            \"nivel_toxicidade\": prob_odio\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        print(f\"Buscando dados do usuário: {username}\")\n",
    "        user = reddit.redditor(username)\n",
    "        \n",
    "        # Verifica se o usuário existe\n",
    "        try:\n",
    "            user_created = user.created_utc\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'erro': f'Usuário {username} não encontrado ou perfil suspenso',\n",
    "                'detalhes': str(e)\n",
    "            }\n",
    "        \n",
    "        comentarios_analisados = 0\n",
    "        total_toxicidade = 0\n",
    "        comentarios_odiosos = 0\n",
    "        historico_comentarios = []\n",
    "        subreddits_atividade = []\n",
    "        comentarios_por_dia = {}\n",
    "        \n",
    "        print(f\"Analisando até {limite} comentários mais recentes...\")\n",
    "        \n",
    "        # Busca os comentários do usuário\n",
    "        try:\n",
    "            for comment in user.comments.new(limit=limite):\n",
    "                if comentarios_analisados >= limite:\n",
    "                    break\n",
    "                \n",
    "                # Pula comentários deletados/removidos\n",
    "                if not comment.body or comment.body in ['[deleted]', '[removed]']:\n",
    "                    continue\n",
    "                \n",
    "                # Analisa a toxicidade do comentário\n",
    "                resultado = avaliar_toxicidade_local(comment.body)\n",
    "                total_toxicidade += resultado[\"nivel_toxicidade\"]\n",
    "                \n",
    "                if resultado[\"odio\"]:\n",
    "                    comentarios_odiosos += 1\n",
    "                \n",
    "                # Converte timestamp para data legível\n",
    "                data_comentario = datetime.fromtimestamp(comment.created_utc, tz=timezone.utc)\n",
    "                data_str = data_comentario.strftime('%Y-%m-%d')\n",
    "                \n",
    "                # Registra atividade por dia\n",
    "                if data_str in comentarios_por_dia:\n",
    "                    comentarios_por_dia[data_str] += 1\n",
    "                else:\n",
    "                    comentarios_por_dia[data_str] = 1\n",
    "                \n",
    "                # Registra subreddit de atividade\n",
    "                subreddits_atividade.append(comment.subreddit.display_name)\n",
    "                \n",
    "                # Salva detalhes do comentário\n",
    "                historico_comentarios.append({\n",
    "                    'texto': comment.body[:200] + \"...\" if len(comment.body) > 200 else comment.body,\n",
    "                    'texto_completo': comment.body,\n",
    "                    'toxicidade': resultado[\"nivel_toxicidade\"],\n",
    "                    'odio': resultado[\"odio\"],\n",
    "                    'subreddit': comment.subreddit.display_name,\n",
    "                    'data': data_str,\n",
    "                    'timestamp': comment.created_utc,\n",
    "                    'score': comment.score,\n",
    "                    'url': f\"https://reddit.com{comment.permalink}\"\n",
    "                })\n",
    "                \n",
    "                comentarios_analisados += 1\n",
    "                \n",
    "                # Pequena pausa para não sobrecarregar a API\n",
    "                if comentarios_analisados % 10 == 0:\n",
    "                    print(f\"Analisados {comentarios_analisados} comentários...\")\n",
    "                    time.sleep(0.1)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao buscar comentários: {e}\")\n",
    "            if comentarios_analisados == 0:\n",
    "                return {\n",
    "                    'erro': f'Não foi possível acessar os comentários de {username}',\n",
    "                    'detalhes': 'Perfil pode ser privado ou sem comentários públicos'\n",
    "                }\n",
    "        \n",
    "        if comentarios_analisados == 0:\n",
    "            return {\n",
    "                'erro': f'Usuário {username} não possui comentários públicos para analisar'\n",
    "            }\n",
    "        \n",
    "        # Calcula estatísticas\n",
    "        nivel_medio_toxicidade = total_toxicidade / comentarios_analisados\n",
    "        percentual_odioso = (comentarios_odiosos / comentarios_analisados) * 100\n",
    "        \n",
    "        # Analisa subreddits mais ativos\n",
    "        subreddits_counter = Counter(subreddits_atividade)\n",
    "        top_subreddits = subreddits_counter.most_common(10)\n",
    "        \n",
    "        # Encontra os comentários mais tóxicos\n",
    "        comentarios_ordenados = sorted(historico_comentarios, \n",
    "                                     key=lambda x: x['toxicidade'], \n",
    "                                     reverse=True)\n",
    "        comentarios_mais_toxicos = comentarios_ordenados[:5]\n",
    "        \n",
    "        # Calcula karma médio dos comentários\n",
    "        scores = [c['score'] for c in historico_comentarios if c['score'] is not None]\n",
    "        karma_medio = sum(scores) / len(scores) if scores else 0\n",
    "        \n",
    "        # Data de criação da conta\n",
    "        data_criacao = datetime.fromtimestamp(user_created, tz=timezone.utc)\n",
    "        dias_desde_criacao = (datetime.now(timezone.utc) - data_criacao).days\n",
    "        \n",
    "        # Classifica o usuário\n",
    "        if percentual_odioso >= 50:\n",
    "            classificacao = \"MUITO TÓXICO\"\n",
    "            cor_classificacao = \"🔴\"\n",
    "        elif percentual_odioso >= 30:\n",
    "            classificacao = \"MODERADAMENTE TÓXICO\"\n",
    "            cor_classificacao = \"🟡\"\n",
    "        elif percentual_odioso >= 10:\n",
    "            classificacao = \"LEVEMENTE TÓXICO\"\n",
    "            cor_classificacao = \"🟠\"\n",
    "        else:\n",
    "            classificacao = \"NÃO TÓXICO\"\n",
    "            cor_classificacao = \"🟢\"\n",
    "        \n",
    "        resultado_final = {\n",
    "            'username': username,\n",
    "            'classificacao': classificacao,\n",
    "            'cor_classificacao': cor_classificacao,\n",
    "            'resumo': {\n",
    "                'total_comentarios_analisados': comentarios_analisados,\n",
    "                'comentarios_odiosos': comentarios_odiosos,\n",
    "                'percentual_odioso': round(percentual_odioso, 2),\n",
    "                'nivel_medio_toxicidade': round(nivel_medio_toxicidade, 4),\n",
    "                'karma_medio_comentarios': round(karma_medio, 2)\n",
    "            },\n",
    "            'perfil': {\n",
    "                'data_criacao_conta': data_criacao.strftime('%Y-%m-%d'),\n",
    "                'dias_desde_criacao': dias_desde_criacao,\n",
    "                'karma_comentarios': user.comment_karma,\n",
    "                'karma_posts': user.link_karma\n",
    "            },\n",
    "            'atividade': {\n",
    "                'subreddits_mais_ativos': top_subreddits,\n",
    "                'comentarios_por_dia': comentarios_por_dia,\n",
    "                'periodo_analisado': f\"{min(comentarios_por_dia.keys())} até {max(comentarios_por_dia.keys())}\" if comentarios_por_dia else \"N/A\"\n",
    "            },\n",
    "            'comentarios_mais_toxicos': comentarios_mais_toxicos,\n",
    "            'historico_completo': historico_comentarios\n",
    "        }\n",
    "        \n",
    "        return resultado_final\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'erro': f'Erro inesperado ao analisar {username}',\n",
    "            'detalhes': str(e)\n",
    "        }\n",
    "\n",
    "def imprimir_relatorio_usuario(resultado):\n",
    "    \n",
    "    if 'erro' in resultado:\n",
    "        print(f\"!!!! ERRO !!!!: {resultado['erro']}\")\n",
    "        if 'detalhes' in resultado:\n",
    "            print(f\"Detalhes: {resultado['detalhes']}\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\" RELATÓRIO DE ANÁLISE DE TOXICIDADE - USUÁRIO: u/{resultado['username']}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    \n",
    "    print(f\"\\n{resultado['cor_classificacao']} CLASSIFICAÇÃO: {resultado['classificacao']}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    print(f\"\\n RESUMO ESTATÍSTICO:\")\n",
    "    print(f\"  • Comentários analisados: {resultado['resumo']['total_comentarios_analisados']}\")\n",
    "    print(f\"  • Comentários ofensivos: {resultado['resumo']['comentarios_odiosos']}\")\n",
    "    print(f\"  • Percentual de toxicidade: {resultado['resumo']['percentual_odioso']:.2f}%\")\n",
    "    print(f\"  • Nível médio de toxicidade: {resultado['resumo']['nivel_medio_toxicidade']:.2f}\")\n",
    "    print(f\"  • Karma médio por comentário: {resultado['resumo']['karma_medio_comentarios']:.1f}\")\n",
    "    \n",
    "    print(\"-\"*80)\n",
    "    print(f\"\\n INFORMAÇÕES DO PERFIL:\")\n",
    "    print(f\"  • Conta criada em: {resultado['perfil']['data_criacao_conta']}\")\n",
    "    print(f\"  • Dias desde criação: {resultado['perfil']['dias_desde_criacao']}\")\n",
    "    print(f\"  • Karma de comentários: {resultado['perfil']['karma_comentarios']:,}\")\n",
    "    print(f\"  • Karma de posts: {resultado['perfil']['karma_posts']:,}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    print(f\"\\n ATIVIDADE POR SUBREDDIT (Top 5):\")\n",
    "    for i, (subreddit, count) in enumerate(resultado['atividade']['subreddits_mais_ativos'][:5], 1):\n",
    "        print(f\"  {i}. r/{subreddit}: {count} comentários\")\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    print(f\"\\n COMENTÁRIOS MAIS TÓXICOS:\")\n",
    "    for i, comentario in enumerate(resultado['comentarios_mais_toxicos'][:3], 1):\n",
    "        print(f\"\\n  {i}. Toxicidade: {comentario['toxicidade']:.2f} | r/{comentario['subreddit']}\")\n",
    "        print(f\"     \\\"{comentario['texto']}\\\"\")\n",
    "        print(f\"     URL: {comentario['url']}\")\n",
    "    \n",
    "    print(f\"\\n PERÍODO ANALISADO: {resultado['atividade']['periodo_analisado']}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Exemplo de uso\n",
    "def exemplo_uso():\n",
    "    \"\"\"\n",
    "    Exemplo de como usar as funções\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "    \n",
    "    load_dotenv()\n",
    "    \n",
    "    # Configuração do Reddit\n",
    "    CLIENT_ID = os.getenv(\"CLIENT_ID\")\n",
    "    CLIENT_SECRET = os.getenv(\"CLIENT_SECRET\")\n",
    "    USER_AGENT = os.getenv(\"USER_AGENT\")\n",
    "    \n",
    "    # Carrega o modelo\n",
    "    try:\n",
    "        model = joblib.load('modelo_odio.joblib')\n",
    "        vectorizer = joblib.load('vetorizador_odio.joblib')\n",
    "    except FileNotFoundError:\n",
    "        print(\"ERRO: Modelos não encontrados. Execute o treinamento primeiro.\")\n",
    "        return\n",
    "    \n",
    "    # Conecta ao Reddit\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=CLIENT_ID,\n",
    "        client_secret=CLIENT_SECRET,\n",
    "        user_agent=USER_AGENT,\n",
    "        check_for_async=False\n",
    "    )\n",
    "    \n",
    "    # Analisa um usuário (substitua pelo username desejado)\n",
    "    username = input(\"Digite o username para analisar (sem u/): \")\n",
    "    \n",
    "    resultado = analisar_perfil_usuario(username, reddit, model, vectorizer, limite=100)\n",
    "    imprimir_relatorio_usuario(resultado)\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    exemplo_uso()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
