{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97b7d796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando o dataset...\n",
      "Dataset carregado com sucesso!\n",
      "   id                                         comentario  anotator1  \\\n",
      "0   1                                       Mais um lixo          1   \n",
      "1   2                    Essa nao tem vergonha na cara!!          1   \n",
      "2   3                     Essa mulher é doente.pilantra!          1   \n",
      "3   4                                Comunista safada...          1   \n",
      "4   5  Vagabunda. Comunista. Mentirosa. O povo chilen...          1   \n",
      "\n",
      "   anotator2  anotator3  label_final  \\\n",
      "0          1          1            1   \n",
      "1          1          1            1   \n",
      "2          1          1            1   \n",
      "3          1          1            1   \n",
      "4          1          1            1   \n",
      "\n",
      "                                 links_post    account_post  \n",
      "0  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
      "1  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
      "2  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
      "3  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
      "4  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
      "\n",
      "Distribuição das classes:\n",
      "label_final\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Iniciando pré-processamento...\n",
      "Dados divididos: 5600 para treino, 1400 para teste.\n",
      "Vetorizando o texto...\n",
      "Treinando o modelo de classificação...\n",
      "Modelo treinado com sucesso!\n",
      "\n",
      "Avaliando o modelo nos dados de teste...\n",
      "\n",
      "Acurácia: 0.8314285714285714\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Não Odioso       0.83      0.83      0.83       700\n",
      "      Odioso       0.83      0.83      0.83       700\n",
      "\n",
      "    accuracy                           0.83      1400\n",
      "   macro avg       0.83      0.83      0.83      1400\n",
      "weighted avg       0.83      0.83      0.83      1400\n",
      "\n",
      "\n",
      "--- MVP PRONTO PARA USO ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# URL do dataset HateBR no GitHub\n",
    "DATASET_URL = 'https://raw.githubusercontent.com/franciellevargas/HateBR/main/dataset/HateBR.csv'\n",
    "\n",
    "# 1. Carregar o dataset\n",
    "print(\"Carregando o dataset...\")\n",
    "try:\n",
    "    df = pd.read_csv(DATASET_URL)\n",
    "    print(\"Dataset carregado com sucesso!\")\n",
    "    # Mostra as primeiras linhas e a distribuição das classes\n",
    "    print(df.head())\n",
    "    print(\"\\nDistribuição das classes:\")\n",
    "    print(df['label_final'].value_counts(normalize=True))\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o dataset: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 2. Pré-processamento e Definição das variáveis\n",
    "print(\"\\nIniciando pré-processamento...\")\n",
    "# Para este MVP, a única limpeza será converter para minúsculas.\n",
    "# O TfidfVectorizer já lida com muita coisa.\n",
    "X = df['comentario'].str.lower()\n",
    "y = df['label_final']\n",
    "\n",
    "# 3. Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Dados divididos: {len(X_train)} para treino, {len(X_test)} para teste.\")\n",
    "\n",
    "# 4. Vetorização do texto usando TF-IDF\n",
    "print(\"Vetorizando o texto...\")\n",
    "vectorizer = TfidfVectorizer(max_features=5000) # Usamos as 5000 palavras mais relevantes\n",
    "\n",
    "# Aprende o vocabulário com os dados de treino e transforma os dados de treino\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Apenas transforma os dados de teste com o vocabulário já aprendido\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# 5. Treinamento do modelo de Regressão Logística\n",
    "print(\"Treinando o modelo de classificação...\")\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vect, y_train)\n",
    "print(\"Modelo treinado com sucesso!\")\n",
    "\n",
    "# 6. Avaliação do modelo\n",
    "print(\"\\nAvaliando o modelo nos dados de teste...\")\n",
    "y_pred = model.predict(X_test_vect)\n",
    "\n",
    "print(\"\\nAcurácia:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Não Odioso', 'Odioso']))\n",
    "\n",
    "# Agora que o modelo está treinado, podemos usá-lo.\n",
    "# Os objetos que precisamos salvar/usar para novas previsões são:\n",
    "# - `model` (o classificador)\n",
    "# - `vectorizer` (o vetorizador)\n",
    "\n",
    "print(\"\\n--- MVP PRONTO PARA USO ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_toxicidade(comentario: str, model, vectorizer) -> dict:\n",
    "    \"\"\"\n",
    "    Recebe um comentário e retorna a classificação de toxicidade\n",
    "    e a probabilidade de ser discurso de ódio.\n",
    "    \"\"\"\n",
    "    # 1. Aplicar o mesmo pré-processamento (minúsculas)\n",
    "    comentario_processado = comentario.lower()\n",
    "    \n",
    "    # 2. Vetorizar o comentário usando o vetorizador JÁ TREINADO\n",
    "    comentario_vect = vectorizer.transform([comentario_processado])\n",
    "    \n",
    "    # 3. Fazer a predição\n",
    "    predicao = model.predict(comentario_vect)\n",
    "    probabilidades = model.predict_proba(comentario_vect)\n",
    "    \n",
    "    # A probabilidade de ser discurso de ódio é a probabilidade da classe \"1\"\n",
    "    prob_odio = probabilidades[0][1]\n",
    "    \n",
    "    if predicao[0] == 1:\n",
    "        classificacao = \"Discurso de Ódio\"\n",
    "    else:\n",
    "        classificacao = \"Não é Discurso de Ódio\"\n",
    "        \n",
    "    return {\n",
    "        \"classificacao\": classificacao,\n",
    "        \"nivel_toxicidade\": f\"{prob_odio:.2%}\" # Formata como porcentagem\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e31c825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testando o MVP com novos comentários ---\n",
      "Comentário: 'Esses políticos são todos uns bandidos, tinham que sumir do mapa!'\n",
      "Resultado: {'classificacao': 'Discurso de Ódio', 'nivel_toxicidade': '88.90%'}\n",
      "\n",
      "Comentário: 'O jogo de futebol ontem foi muito emocionante, gostei bastante do resultado.'\n",
      "Resultado: {'classificacao': 'Não é Discurso de Ódio', 'nivel_toxicidade': '35.25%'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(\"Digite um comentário para ser analisado (ou \\'sair\\' para terminar):\")\\nwhile True:\\n    meu_comentario = input(\"> \")\\n    if meu_comentario.lower() == \\'sair\\':\\n        break\\n    resultado = avaliar_toxicidade(meu_comentario, model, vectorizer)\\n    print(f\"Resultado: {resultado}\\n\")'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- EXEMPLOS DE USO ---\n",
    "print(\"\\n--- Testando o MVP com novos comentários ---\")\n",
    "\n",
    "# Exemplo 1: Comentário potencialmente tóxico\n",
    "comentario1 = \"Esses políticos são todos uns bandidos, tinham que sumir do mapa!\"\n",
    "resultado1 = avaliar_toxicidade(comentario1, model, vectorizer)\n",
    "print(f\"Comentário: '{comentario1}'\")\n",
    "print(f\"Resultado: {resultado1}\\n\")\n",
    "\n",
    "# Exemplo 2: Comentário neutro\n",
    "comentario2 = \"O jogo de futebol ontem foi muito emocionante, gostei bastante do resultado.\"\n",
    "resultado2 = avaliar_toxicidade(comentario2, model, vectorizer)\n",
    "print(f\"Comentário: '{comentario2}'\")\n",
    "print(f\"Resultado: {resultado2}\\n\")\n",
    "\n",
    "# Exemplo 3: Comentário inserido pelo usuário\n",
    "'''print(\"Digite um comentário para ser analisado (ou 'sair' para terminar):\")\n",
    "while True:\n",
    "    meu_comentario = input(\"> \")\n",
    "    if meu_comentario.lower() == 'sair':\n",
    "        break\n",
    "    resultado = avaliar_toxicidade(meu_comentario, model, vectorizer)\n",
    "    print(f\"Resultado: {resultado}\\n\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b2b927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salvando o modelo e o vetorizador em arquivos...\n",
      "Modelo e vetorizador salvos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# (Após o bloco de treinamento e avaliação do modelo...)\n",
    "import joblib\n",
    "\n",
    "print(\"\\nSalvando o modelo e o vetorizador em arquivos...\")\n",
    "\n",
    "# Salva o modelo treinado\n",
    "joblib.dump(model, 'modelo_odio.joblib')\n",
    "\n",
    "# Salva o vetorizador\n",
    "joblib.dump(vectorizer, 'vetorizador_odio.joblib')\n",
    "\n",
    "print(\"Modelo e vetorizador salvos com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51a4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo e vetorizador carregados com sucesso.\n",
      "\n",
      "--- INICIANDO ANÁLISE DE TOXICIDADE NO X ---\n",
      "Conexão com a API do X estabelecida.\n",
      "\n",
      "--- Analisando @felipeneto ---\n",
      "Ocorreu um erro ao buscar tweets de @felipeneto: 429 Too Many Requests\n",
      "Too Many Requests\n",
      "\n",
      "--- Analisando @casimiro ---\n",
      "Ocorreu um erro ao buscar tweets de @casimiro: 429 Too Many Requests\n",
      "Too Many Requests\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "\n",
    "# --- CONFIGURAÇÃO ---\n",
    "# Carregue o Bearer Token. É uma boa prática usar variáveis de ambiente.\n",
    "# Para testar, você pode simplesmente colocar a string aqui:\n",
    "# BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAHVr3wEAAAAAp2KKTt18ViS4Iy%2FseFXPFWMyA%2FA%3D07WZY4kChG6WCj7FJDMTCzimB1a2tKADe5HPzkgos7FR7UdLNM\"\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAHVr3wEAAAAAp2KKTt18ViS4Iy%2FseFXPFWMyA%2FA%3D07WZY4kChG6WCj7FJDMTCzimB1a2tKADe5HPzkgos7FR7UdLNM\"\n",
    "\n",
    "if not BEARER_TOKEN:\n",
    "    print(\"ERRO: O Bearer Token não foi encontrado.\")\n",
    "    print(\"Por favor, defina a variável de ambiente TWITTER_BEARER_TOKEN ou insira-a diretamente no código.\")\n",
    "    exit()\n",
    "\n",
    "# Carregar o modelo e o vetorizador salvos\n",
    "try:\n",
    "    model = joblib.load('modelo_odio.joblib')\n",
    "    vectorizer = joblib.load('vetorizador_odio.joblib')\n",
    "    print(\"Modelo e vetorizador carregados com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERRO: Arquivos 'modelo_odio.joblib' ou 'vetorizador_odio.joblib' não encontrados.\")\n",
    "    print(\"Certifique-se de executar o script de treinamento primeiro.\")\n",
    "    exit()\n",
    "\n",
    "# --- FUNÇÕES ---\n",
    "\n",
    "def avaliar_toxicidade_x(comentario: str) -> dict:\n",
    "    \"\"\"\n",
    "    Recebe um comentário e retorna a classificação de toxicidade\n",
    "    e a probabilidade de ser discurso de ódio.\n",
    "    \"\"\"\n",
    "    comentario_processado = comentario.lower()\n",
    "    comentario_vect = vectorizer.transform([comentario_processado])\n",
    "    predicao = model.predict(comentario_vect)\n",
    "    probabilidades = model.predict_proba(comentario_vect)\n",
    "    prob_odio = probabilidades[0][1]\n",
    "    \n",
    "    return {\n",
    "        \"eh_odio\": predicao[0] == 1,\n",
    "        \"nivel_toxicidade\": prob_odio\n",
    "    }\n",
    "\n",
    "def buscar_tweets_usuario(client, username: str, count: int = 20):\n",
    "    \"\"\"\n",
    "    Busca os tweets mais recentes de um usuário.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Encontrar o ID do usuário a partir do nome de usuário\n",
    "        user_response = client.get_user(username=username)\n",
    "        if not user_response.data:\n",
    "            print(f\"Usuário '{username}' não encontrado.\")\n",
    "            return None\n",
    "        user_id = user_response.data.id\n",
    "\n",
    "        # 2. Buscar os tweets, excluindo respostas e retweets\n",
    "        tweets_response = client.get_users_tweets(\n",
    "            id=user_id,\n",
    "            max_results=count,\n",
    "            exclude=['replies', 'retweets'],\n",
    "            tweet_fields=['text']\n",
    "        )\n",
    "        return tweets_response.data\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro ao buscar tweets de @{username}: {e}\")\n",
    "        return None\n",
    "\n",
    "def limpar_tweet(texto: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove links, menções e outros ruídos do texto do tweet.\n",
    "    \"\"\"\n",
    "    texto = re.sub(r'http\\S+|www\\S+|https\\S+', '', texto, flags=re.MULTILINE)\n",
    "    texto = re.sub(r'\\@\\w+', '', texto)\n",
    "    texto = re.sub(r'#', '', texto)\n",
    "    texto = texto.strip()\n",
    "    return texto\n",
    "\n",
    "# --- EXECUÇÃO PRINCIPAL ---\n",
    "\n",
    "def main():\n",
    "    print(\"\\n--- INICIANDO ANÁLISE DE TOXICIDADE NO X ---\")\n",
    "    \n",
    "    # Conectar à API\n",
    "    try:\n",
    "        client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "        print(\"Conexão com a API do X estabelecida.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao conectar com a API do X: {e}\")\n",
    "        return\n",
    "\n",
    "    # Alvos da análise\n",
    "    alvos = [\"felipeneto\", \"casimiro\"]\n",
    "    num_tweets_para_analisar = 20 # Pode aumentar ou diminuir\n",
    "\n",
    "    for usuario in alvos:\n",
    "        print(f\"\\n--- Analisando @{usuario} ---\")\n",
    "        \n",
    "        tweets = buscar_tweets_usuario(client, usuario, count=num_tweets_para_analisar)\n",
    "        \n",
    "        if not tweets:\n",
    "            continue\n",
    "\n",
    "        total_toxicidade = 0\n",
    "        tweets_odiosos = 0\n",
    "        \n",
    "        for i, tweet in enumerate(tweets):\n",
    "            texto_limpo = limpar_tweet(tweet.text)\n",
    "            if not texto_limpo:\n",
    "                continue\n",
    "\n",
    "            resultado = avaliar_toxicidade_x(texto_limpo)\n",
    "            total_toxicidade += resultado[\"nivel_toxicidade\"]\n",
    "            if resultado[\"eh_odio\"]:\n",
    "                tweets_odiosos += 1\n",
    "                # Descomente a linha abaixo para ver os tweets classificados como odiosos\n",
    "                # print(f\"  [ODIOSO DETECTADO] Prob: {resultado['nivel_toxicidade']:.2%} | Tweet: {texto_limpo[:50]}...\")\n",
    "\n",
    "        # Relatório final para o usuário\n",
    "        num_analisados = len(tweets)\n",
    "        media_toxicidade = (total_toxicidade / num_analisados) if num_analisados > 0 else 0\n",
    "        \n",
    "        print(f\"Relatório Final para @{usuario}:\")\n",
    "        print(f\"  - Tweets recentes analisados: {num_analisados}\")\n",
    "        print(f\"  - Tweets classificados como discurso de ódio: {tweets_odiosos}\")\n",
    "        print(f\"  - Nível médio de toxicidade: {media_toxicidade:.2%}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
